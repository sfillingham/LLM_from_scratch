{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e12937-664b-471d-8c54-71eca9eec3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model_architecture import GPTModel, GPTModel_DyT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f823671-0208-465f-83f9-3f4e9ac5ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 256, # This is non-standard, using for training purposes (1024 is normal for GPT-2 models)\n",
    "    'emb_dim': 768,\n",
    "    'n_heads': 12,\n",
    "    'n_layers': 12,\n",
    "    'drop_rate_emb': 0.1,\n",
    "    'drop_rate_shortcut': 0.1,\n",
    "    'drop_rate_attn': 0.1,\n",
    "    'qkv_bias': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "849cc613-eef0-4ffe-a377-59cf77dc55da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel_DyT(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock_DyT(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dyt1): DyT()\n",
       "      (dyt2): DyT()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): DyT()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "model_dyt = GPTModel_DyT(GPT_CONFIG_124M)\n",
    "model_dyt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee62e825-906f-4074-8e4a-29fc4bf89f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from model_architecture import generate_text_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07383a9e-0a6f-463a-82fa-28c8e8aab0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c89584-1459-4d0b-ae0f-09c9377e4b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(f\"Output text:\\n {token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf58b92-9499-411d-a86d-cdab977a661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Verdict story for training and validation\n",
    "# Later explore training on a larger dataset to test the capability of the M4 Pro chip\n",
    "\n",
    "file_path = 'the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bd9ed65-fe8a-448b-a882-7d31e6ae3136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Characters: {total_characters}\")\n",
    "print(f\"Tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f05f14d1-2a73-4995-b719-f2160471c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f2da94-b382-4b8b-a099-fab5e9b9bca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11d3fd650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_loaders import create_dataloader_v1\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c8f734-555a-4286-baf2-8cc37c9bea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batchsize=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batchsize=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f108fe3f-6fa3-4891-863d-815650b06b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2feed57-6831-4433-a4e5-2789cde16df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c67e725e-5d82-467e-9d68-9ca971e0ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb161fec-a238-47c8-96ec-03c2bdf73f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.16638348168796963\n",
      "Validation loss: 6.711029529571533\n",
      "Training loss DyT: 10.865442276000977\n",
      "Validation loss DytT: 10.871414184570312\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model_dyt.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "    train_loss_dyt = calc_loss_loader(train_loader, model_dyt, device)\n",
    "    val_loss_dyt = calc_loss_loader(val_loader, model_dyt, device)\n",
    "    \n",
    "print(f\"Training loss: {train_loss}\")\n",
    "print(f\"Validation loss: {val_loss}\")\n",
    "print(f\"Training loss DyT: {train_loss_dyt}\")\n",
    "print(f\"Validation loss DytT: {val_loss_dyt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16e0ea3e-9d11-4bf7-be87-af3f884f5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() #Turns off dropout layers in the model for evaluation\n",
    "    with torch.no_grad(): #Turns off gradient tracking in torch to reduce computational overhead\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "    \n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n', ' '))\n",
    "    model.train()\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader,\n",
    "                                                      val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}), \"\n",
    "                      f\"Val loss {val_loss:.3f})\"\n",
    "                )\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a54fa4aa-a091-474b-8631-4a6651338509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.464), Val loss 7.254)\n",
      "Ep 1 (Step 000005): Train loss 0.227), Val loss 6.892)\n",
      "Every effort moves you?\" \"I and pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\" He was _not_ interesting--if I saw that, my eye fell on a small picture\n",
      "Ep 2 (Step 000010): Train loss 0.163), Val loss 7.026)\n",
      "Ep 2 (Step 000015): Train loss 0.153), Val loss 6.885)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, I remember getting off a prodigious phrase about the sketch of the donkey. \"There were days when I\n",
      "Ep 3 (Step 000020): Train loss 0.104), Val loss 7.100)\n",
      "Ep 3 (Step 000025): Train loss 0.092), Val loss 7.031)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, when I back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 4 (Step 000030): Train loss 0.071), Val loss 7.219)\n",
      "Ep 4 (Step 000035): Train loss 0.056), Val loss 7.261)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 5 (Step 000040): Train loss 0.048), Val loss 7.375)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 6 (Step 000045): Train loss 0.030), Val loss 7.416)\n",
      "Ep 6 (Step 000050): Train loss 0.024), Val loss 7.503)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 7 (Step 000055): Train loss 0.027), Val loss 7.566)\n",
      "Ep 7 (Step 000060): Train loss 0.021), Val loss 7.631)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 8 (Step 000065): Train loss 0.022), Val loss 7.602)\n",
      "Ep 8 (Step 000070): Train loss 0.019), Val loss 7.686)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 0.027), Val loss 7.763)\n",
      "Ep 9 (Step 000080): Train loss 0.020), Val loss 7.713)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch, married a rich widow, and established himself in\n",
      "Ep 10 (Step 000085): Train loss 0.036), Val loss 7.625)\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "# Train a simple model for 10 epochs\n",
    "torch.manual_seed(123)\n",
    "#Model defined above, uncomment if this isn't true\n",
    "#model = GPTModel(GPT_CONFIG_124M)\n",
    "#model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context='Every effort moves you', tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# train_losses_dyt, val_losses_dyt, tokens_seen_dyt = train_model_simple(\n",
    "#     model_dyt, train_loader, val_loader, optimizer, device,\n",
    "#     num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "#     start_context='Every effort moves you', tokenizer=tokenizer\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92bfa89b-ed70-4917-989a-a242ce096b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(6,4))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle='-.', label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel('Tokens seen')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92a07b16-99e4-4c60-8129-a93c6a4de6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "#plot_losses(epochs_tensor, tokens_seen_dyt, train_losses_dyt, val_losses_dyt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3d38e-23d6-4d8d-a501-50f6a4899423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21261c-2990-44be-8514-ab683d4b06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: \n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ca8136d-584b-41f2-b642-608feb9803f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1171cfb10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from model_architecture import generate\n",
    "\n",
    "# torch.manual_seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4b20c34-4d86-4b38-bd12-a84c7b101c0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eod_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m generate(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     idx\u001b[38;5;241m=\u001b[39mtext_to_token_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvery effort moves you\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer),\n\u001b[1;32m      4\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      5\u001b[0m     context_size\u001b[38;5;241m=\u001b[39mGPT_CONFIG_124M[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m      7\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.4\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput text: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, token_ids_to_text(token_ids, tokenizer))\n",
      "File \u001b[0;32m/Volumes/MacMini/llm_from_scratch/LLM_from_scratch/model_architecture.py:204\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, idx, max_new_tokens, context_size, temperature, top_k, eos_id)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     idx_next \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx_next \u001b[38;5;241m==\u001b[39m eod_id:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    206\u001b[0m idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((idx, idx_next), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eod_id' is not defined"
     ]
    }
   ],
   "source": [
    "# token_ids = generate(\n",
    "#     model=model,\n",
    "#     idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "#     max_new_tokens=5,\n",
    "#     context_size=GPT_CONFIG_124M['context_length'],\n",
    "#     top_k=25,\n",
    "#     temperature=1.4\n",
    "# )\n",
    "# print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19147fef-e217-44ed-8dc0-364caf3a2f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

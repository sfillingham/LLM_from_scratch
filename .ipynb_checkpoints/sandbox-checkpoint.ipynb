{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f6466d-dc35-485a-87b1-9ec8d52c33e6",
   "metadata": {},
   "source": [
    "### Chapter 2 problems and Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe13bc9-2f18-40c4-99db-a61de055435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "from importlib import reload\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3094859-b41e-4215-a3f0-635f2d547f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tiktoken version: {version('tiktoken')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b804ab2-d906-4fb1-a4ba-fe6418e60d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdca446e-53de-45b1-9d7d-c1f8e8f6a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6a19b4-71e0-448a-99f0-6b70c90f228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb8720c-a7da-4419-8b17-e8c2286beed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4032c-c44c-4ef4-b0f4-e07ca691e8fa",
   "metadata": {},
   "source": [
    "**Problem 2.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cfe4592-4581-4c81-a8f6-5ecf648dd05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n"
     ]
    }
   ],
   "source": [
    "text = 'Akwirw ier'\n",
    "integers = tokenizer.encode(text)\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65a2537-6839-4c01-a3ac-ae247aa17f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33901: Ak\n",
      "86: w\n",
      "343: ir\n",
      "86: w\n",
      "220:  \n",
      "959: ier\n"
     ]
    }
   ],
   "source": [
    "for i in integers:\n",
    "    print(f\"{i}: {tokenizer.decode([i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be6f23e-57cf-418c-986d-b37521a20dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akwirw ier\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74504843-95d1-4828-af7d-76470e13445a",
   "metadata": {},
   "source": [
    "**Problem 2.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f7fe03-6d4d-4e02-a96b-ceae9cfec2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8045f76f-112f-42ba-ac0b-d22969d29fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the-verdict.txt', 'r') as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bafbeb5-5769-4ebd-a707-1146998c47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batchsize=8, max_length=4, stride=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74bd9a70-1932-4fe0-bf48-5779fcdee6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c23c3d9-65d2-466e-b693-35a453a17c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell for the specific answers to problem 2.2\n",
    "#first_batch = next(data_iter)\n",
    "#print(first_batch)\n",
    "#second_batch = next(data_iter)\n",
    "#print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9eccc3-3814-46e5-92d3-955953cadff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43ed568f-7112-413b-b2c6-e86146c87415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]], dtype=torch.int32)\n",
      "Targets: \n",
      "tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inputs: \\n{inputs}\")\n",
    "print(f\"Targets: \\n{targets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976d76c-d57f-4eb0-af64-25b1e8df681f",
   "metadata": {},
   "source": [
    "### Practice Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "154672eb-7965-45f2-8ff7-d0f3f1d6fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16af2011-30fb-4b35-9ce4-28e11bc34d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01af59da-37d9-433e-b8af-42c2369f24e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 4\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "pos_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4134ffee-a5e6-4455-b98d-0dcaeaed00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd979b-b0de-42e5-b6a6-dc191a744948",
   "metadata": {},
   "source": [
    "### Chapter 3 Problems and Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b8e3bf6-d60b-4a54-9242-905a1f5e4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89],\n",
    "     [0.55, 0.87, 0.66],\n",
    "     [0.57, 0.85, 0.64],\n",
    "     [0.22, 0.58, 0.33],\n",
    "     [0.77, 0.25, 0.10],\n",
    "     [0.05, 0.80, 0.55]]\n",
    ")\n",
    "\n",
    "from attention_heads import SelfAttention_v2\n",
    "from attention_heads import SelfAttention_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9e65dff-8627-4ea0-a5b6-3d70c6baf778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10c3e1a70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(789)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c38fe-11dc-4d95-acf7-7937fbf940c5",
   "metadata": {},
   "source": [
    "**Problem 3.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b2f030a-cb72-4c4f-9fb1-a538c01c0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_v2 = SelfAttention_v2(3, 2)\n",
    "sa_v1 = SelfAttention_v1(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4dd86b4-5816-4914-a014-8de0cb5f4c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0adb28e1-424a-4679-9352-6235da11a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0177, 0.5637],\n",
      "        [1.0427, 0.5773],\n",
      "        [1.0428, 0.5774],\n",
      "        [1.0153, 0.5620],\n",
      "        [1.0286, 0.5701],\n",
      "        [1.0162, 0.5622]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#showing it naively produces the wrong outputs\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75fb955f-3d33-49c1-8bd6-ed70490f4170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3161, -0.1683],\n",
      "        [ 0.4568, -0.3379],\n",
      "        [ 0.5118, -0.0918]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# assigning the v2 parameters to the W matrices of the v1 instance\n",
    "# Transpose the weight matrix of nn.Linear object, then turn it back into a nn.Parameter object\n",
    "w_query_temp = sa_v2.W_query.weight\n",
    "w_key_temp = sa_v2.W_key.weight\n",
    "w_value_temp = sa_v2.W_value.weight\n",
    "print(nn.Parameter(w_query_temp.T))\n",
    "\n",
    "sa_v1.W_query = nn.Parameter(w_query_temp.T)\n",
    "sa_v1.W_key = nn.Parameter(w_key_temp.T)\n",
    "sa_v1.W_value = nn.Parameter(w_value_temp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9d45595-de48-4a28-8fa6-8ae89e03317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# verify that the v1 output now matches the v2 output\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a715d302-c5a0-424b-904a-34891498c79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88e1c0c0-f638-4b74-a23c-60701f7fc640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_weights.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8b2b1f8-0590-45e7-a50f-927bf6bb4855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "examples = torch.ones(6,6)\n",
    "print(dropout(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a83b222-66ef-48b9-9c43-839d834f7b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3843, 0.3293, 0.0000, 0.3100, 0.3442, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2992, 0.0000, 0.2955],\n",
      "        [0.4071, 0.3318, 0.3325, 0.2996, 0.0000, 0.2961],\n",
      "        [0.0000, 0.3334, 0.3337, 0.0000, 0.0000, 0.3128],\n",
      "        [0.0000, 0.3337, 0.0000, 0.3177, 0.0000, 0.3169],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "406dd8d0-dca5-49e3-89c3-eff72a9c1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46bfa0b-18ec-4df5-95c9-6e9217ef4417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

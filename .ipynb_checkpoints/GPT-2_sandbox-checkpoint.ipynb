{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f6466d-dc35-485a-87b1-9ec8d52c33e6",
   "metadata": {},
   "source": [
    "### Chapter 2 Exercises and Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe13bc9-2f18-40c4-99db-a61de055435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "from importlib import reload\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3094859-b41e-4215-a3f0-635f2d547f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tiktoken version: {version('tiktoken')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b804ab2-d906-4fb1-a4ba-fe6418e60d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdca446e-53de-45b1-9d7d-c1f8e8f6a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6a19b4-71e0-448a-99f0-6b70c90f228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb8720c-a7da-4419-8b17-e8c2286beed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4032c-c44c-4ef4-b0f4-e07ca691e8fa",
   "metadata": {},
   "source": [
    "**Exercise 2.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cfe4592-4581-4c81-a8f6-5ecf648dd05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n"
     ]
    }
   ],
   "source": [
    "text = 'Akwirw ier'\n",
    "integers = tokenizer.encode(text)\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65a2537-6839-4c01-a3ac-ae247aa17f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33901: Ak\n",
      "86: w\n",
      "343: ir\n",
      "86: w\n",
      "220:  \n",
      "959: ier\n"
     ]
    }
   ],
   "source": [
    "for i in integers:\n",
    "    print(f\"{i}: {tokenizer.decode([i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be6f23e-57cf-418c-986d-b37521a20dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akwirw ier\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74504843-95d1-4828-af7d-76470e13445a",
   "metadata": {},
   "source": [
    "**Exercise 2.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f7fe03-6d4d-4e02-a96b-ceae9cfec2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8045f76f-112f-42ba-ac0b-d22969d29fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the-verdict.txt', 'r') as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bafbeb5-5769-4ebd-a707-1146998c47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batchsize=8, max_length=4, stride=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74bd9a70-1932-4fe0-bf48-5779fcdee6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c23c3d9-65d2-466e-b693-35a453a17c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell for the specific answers to problem 2.2\n",
    "#first_batch = next(data_iter)\n",
    "#print(first_batch)\n",
    "#second_batch = next(data_iter)\n",
    "#print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9eccc3-3814-46e5-92d3-955953cadff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43ed568f-7112-413b-b2c6-e86146c87415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]], dtype=torch.int32)\n",
      "Targets: \n",
      "tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inputs: \\n{inputs}\")\n",
    "print(f\"Targets: \\n{targets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976d76c-d57f-4eb0-af64-25b1e8df681f",
   "metadata": {},
   "source": [
    "#### Practice Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "154672eb-7965-45f2-8ff7-d0f3f1d6fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16af2011-30fb-4b35-9ce4-28e11bc34d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01af59da-37d9-433e-b8af-42c2369f24e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 4\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "pos_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4134ffee-a5e6-4455-b98d-0dcaeaed00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd979b-b0de-42e5-b6a6-dc191a744948",
   "metadata": {},
   "source": [
    "### Chapter 3 Exercises and Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b8e3bf6-d60b-4a54-9242-905a1f5e4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89],\n",
    "     [0.55, 0.87, 0.66],\n",
    "     [0.57, 0.85, 0.64],\n",
    "     [0.22, 0.58, 0.33],\n",
    "     [0.77, 0.25, 0.10],\n",
    "     [0.05, 0.80, 0.55]]\n",
    ")\n",
    "\n",
    "from attention_heads import SelfAttention_v2\n",
    "from attention_heads import SelfAttention_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9e65dff-8627-4ea0-a5b6-3d70c6baf778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x123339a70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(789)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c38fe-11dc-4d95-acf7-7937fbf940c5",
   "metadata": {},
   "source": [
    "**Exercise 3.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2f030a-cb72-4c4f-9fb1-a538c01c0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_v2 = SelfAttention_v2(3, 2)\n",
    "sa_v1 = SelfAttention_v1(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4dd86b4-5816-4914-a014-8de0cb5f4c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0adb28e1-424a-4679-9352-6235da11a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0177, 0.5637],\n",
      "        [1.0427, 0.5773],\n",
      "        [1.0428, 0.5774],\n",
      "        [1.0153, 0.5620],\n",
      "        [1.0286, 0.5701],\n",
      "        [1.0162, 0.5622]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#showing it naively produces the wrong outputs\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75fb955f-3d33-49c1-8bd6-ed70490f4170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3161, -0.1683],\n",
      "        [ 0.4568, -0.3379],\n",
      "        [ 0.5118, -0.0918]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# assigning the v2 parameters to the W matrices of the v1 instance\n",
    "# Transpose the weight matrix of nn.Linear object, then turn it back into a nn.Parameter object\n",
    "w_query_temp = sa_v2.W_query.weight\n",
    "w_key_temp = sa_v2.W_key.weight\n",
    "w_value_temp = sa_v2.W_value.weight\n",
    "print(nn.Parameter(w_query_temp.T))\n",
    "\n",
    "sa_v1.W_query = nn.Parameter(w_query_temp.T)\n",
    "sa_v1.W_key = nn.Parameter(w_key_temp.T)\n",
    "sa_v1.W_value = nn.Parameter(w_value_temp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9d45595-de48-4a28-8fa6-8ae89e03317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# verify that the v1 output now matches the v2 output\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a715d302-c5a0-424b-904a-34891498c79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88e1c0c0-f638-4b74-a23c-60701f7fc640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_weights.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8b2b1f8-0590-45e7-a50f-927bf6bb4855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "examples = torch.ones(6,6)\n",
    "print(dropout(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a83b222-66ef-48b9-9c43-839d834f7b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3843, 0.3293, 0.0000, 0.3100, 0.3442, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2992, 0.0000, 0.2955],\n",
      "        [0.4071, 0.3318, 0.3325, 0.2996, 0.0000, 0.2961],\n",
      "        [0.0000, 0.3334, 0.3337, 0.0000, 0.0000, 0.3128],\n",
      "        [0.0000, 0.3337, 0.0000, 0.3177, 0.0000, 0.3169],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "406dd8d0-dca5-49e3-89c3-eff72a9c1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6614ec8-27b6-4870-b017-ad8dd6a91f27",
   "metadata": {},
   "source": [
    "### Chapter 4 Exercises and Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d91862c3-2dd5-4d51-83af-a74659617420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "batch = []\n",
    "txt1 = 'Every effort moves you'\n",
    "txt2 = 'Every day holds a'\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a46bfa0b-18ec-4df5-95c9-6e9217ef4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_architecture import TransformerBlock\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 1024,\n",
    "    'emb_dim': 768,\n",
    "    'n_heads': 12,\n",
    "    'n_layers': 12,\n",
    "    'drop_rate': 0.1,\n",
    "    'qkv_bias': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4845df42-7a6f-4c9e-8c1e-016c24354d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe331b9b-671d-4f0a-a660-ea0abd73f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7069230-b349-43d9-855d-8fea15beaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_architecture import GPTModel\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9aa599a-4a36-4f54-8bb5-f7b1fe5cf903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch: \n",
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = model(batch)\n",
    "print(f\"Input batch: \\n{batch}\")\n",
    "print(f\"\\nOutput shape: {out.shape}\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "944ed6d7-9d25-4649-aae7-c4a738a0684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a254d52-75ab-4d26-88ec-6ed8a31ec9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embeddings layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7e504-2ef5-4620-82f0-b67fe1157d74",
   "metadata": {},
   "source": [
    "**Exercise 4.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "178555c2-d30f-4051-a83e-7209c6e5d5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feed forward paramters: 56,669,184\n",
      "Feed forward paramters per block: 4,722,432\n",
      "Total multi-head attention parameters: 28,320,768\n",
      "Multi-head attention parameters per block: 2,360,064\n"
     ]
    }
   ],
   "source": [
    "total_params_ff = 0\n",
    "for el in model.trf_blocks:\n",
    "    total_params_ff += sum(p.numel() for p in el.ff.parameters())\n",
    "print(f\"Total feed forward paramters: {total_params_ff:,}\")\n",
    "print(f\"Feed forward paramters per block: {total_params_ff//12:,}\")\n",
    "\n",
    "total_params_att = 0\n",
    "for el in model.trf_blocks:\n",
    "    total_params_att += sum(p.numel() for p in el.att.parameters())\n",
    "print(f\"Total multi-head attention parameters: {total_params_att:,}\")\n",
    "print(f\"Multi-head attention parameters per block: {total_params_att//12:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e599afd-0b9b-4441-9593-160bb19342ca",
   "metadata": {},
   "source": [
    "**Exercise 4.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e2dd5f3-2f3b-4b00-ae79-dcedd53c6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_MED = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 1024,\n",
    "    'emb_dim': 1024,\n",
    "    'n_heads': 16,\n",
    "    'n_layers': 24,\n",
    "    'drop_rate': 0.1,\n",
    "    'qkv_bias': False,\n",
    "}\n",
    "GPT_CONFIG_LARGE = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 1024,\n",
    "    'emb_dim': 1280,\n",
    "    'n_heads': 20,\n",
    "    'n_layers': 36,\n",
    "    'drop_rate': 0.1,\n",
    "    'qkv_bias': False,\n",
    "}\n",
    "GPT_CONFIG_XLARGE = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 1024,\n",
    "    'emb_dim': 1600,\n",
    "    'n_heads': 25,\n",
    "    'n_layers': 48,\n",
    "    'drop_rate': 0.1,\n",
    "    'qkv_bias': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2001e801-3bdf-40d6-8d0d-e32034305313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_med = GPTModel(GPT_CONFIG_MED)\n",
    "model_large = GPTModel(GPT_CONFIG_LARGE)\n",
    "model_xlarge = GPTModel(GPT_CONFIG_XLARGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a0004c5-bc58-4509-81c7-6482d47707ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters for GPT-2 Medium: 406,212,608\n",
      "Total number of parameters for GPT-2 Large: 838,220,800\n",
      "Total number of parameters for GPT-2 X-Large: 1,637,792,000\n"
     ]
    }
   ],
   "source": [
    "total_params_med = sum(p.numel() for p in model_med.parameters())\n",
    "total_params_large = sum(p.numel() for p in model_large.parameters())\n",
    "total_params_xlarge = sum(p.numel() for p in model_xlarge.parameters())\n",
    "\n",
    "print(f\"Total number of parameters for GPT-2 Medium: {total_params_med:,}\")\n",
    "print(f\"Total number of parameters for GPT-2 Large: {total_params_large:,}\")\n",
    "print(f\"Total number of parameters for GPT-2 X-Large: {total_params_xlarge:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75d69a8d-4ce9-4bdf-b297-7d915da043eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b5159-6876-4146-80fd-52e1b5a72165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
